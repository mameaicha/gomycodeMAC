{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from rake_nltk import Rake\n",
    "import os\n",
    "import docx\n",
    "import PyPDF2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "#from PIL import Image\n",
    "\n",
    "import sys\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "#from pdfminer.high_level import extract_text\n",
    "#from PyPDF2 import PdfReader, PdfFileWriter, PdfFileMerger\n",
    "\n",
    "\n",
    "# Load Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update with your Tesseract installation path\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from nanonets import NANONETSOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_text_from_pdf: This function takes a PDF file path as input and extracts text from all the pages in the PDF using PyPDF2.\n",
    "\n",
    "def extract_text_from_pdf_or_image(pdf_path):\n",
    "    model = NANONETSOCR()\n",
    "    model.set_token('87dcd5e7-53e9-11ee-bb5e-c26e11187d6d')\n",
    "    text = model.convert_to_string(pdf_path,formatting='lines') \n",
    "    return text\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     with open(pdf_path, 'rb') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         text = ''\n",
    "#         for page in pdf_reader.pages:\n",
    "#             text += page.extract_text()\n",
    "#     return text\n",
    "\n",
    "#extract_text_from_docx: This function takes a DOCX file path as input and extracts text from the document using the docx library.\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "# #extract_text_from_image: This function takes an image file path as input, converts the image to grayscale, and then uses pytesseract to perform Optical Character Recognition (OCR) and extract text from the image.\n",
    "# #Load the resume image using OpenCV and use OCR to extract text from the image\n",
    "# def extract_text_from_image(image_path):\n",
    "#     # Load the image using OpenCV\n",
    "#     image = cv2.imread(image_path)\n",
    "#     # Convert the image to grayscale\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     # Perform OCR to extract text\n",
    "#     text = pytesseract.image_to_string(gray)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================Extracting person's name==============================================\n",
    "\n",
    "def extract_names(txt):\n",
    "    person_names = []\n",
    "    for sent in nltk.sent_tokenize(txt):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "                person_names.append(\n",
    "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
    "                )\n",
    "    return person_names[0]\n",
    "\n",
    "\n",
    "#========================Extracting phone number========================================== \n",
    "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
    " \n",
    "def extract_phone_number(resume_text):\n",
    "    phone = re.findall(PHONE_REG, resume_text)\n",
    " \n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    " \n",
    "        if resume_text.find(number)  >= 0 and len(number) < 16:\n",
    "            return number\n",
    "    return None\n",
    "\n",
    "\n",
    "#========================Extracting email==========================================\n",
    "\n",
    "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    " \n",
    "def extract_emails(resume_text):\n",
    "    return re.findall(EMAIL_REG, resume_text)\n",
    "\n",
    "\n",
    "#========================Extracting education=========================================\n",
    "\n",
    "RESERVED_WORDS = [\n",
    "    'school',\n",
    "    'college',\n",
    "    'university',\n",
    "    'academy',\n",
    "    'faculty',\n",
    "    'degree',\n",
    "    'institute',]\n",
    " \n",
    "def extract_education(input_text):\n",
    "    organizations = []\n",
    " \n",
    "    # first get all the organization names using nltk\n",
    "    for sent in nltk.sent_tokenize(input_text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
    "                organizations.append(' '.join(c[0] for c in chunk.leaves()))\n",
    " \n",
    "    # we search for each bigram and trigram for reserved words\n",
    "    # (college, university etc...)\n",
    "    education = set()\n",
    "    for org in organizations:\n",
    "        for word in RESERVED_WORDS:\n",
    "            if org.lower().find(word) >= 0:\n",
    "                education.add(org)\n",
    " \n",
    "    return education \n",
    "\n",
    "\n",
    "#========================Extracting skills================================================\n",
    "SKILLS_DB = [\n",
    "    'andriod developer',\n",
    "    'app developer',\n",
    "    'Javascript',\n",
    "    'Java',\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'python',\n",
    "    'CSS',\n",
    "    'doctor',\n",
    "    'teacher',\n",
    "    'web development',\n",
    "    'communication',\n",
    "    'team work',\n",
    "]\n",
    "\n",
    "def extract_skills(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    "    \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "    \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "    found_skills = set()\n",
    "\n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in SKILLS_DB:\n",
    "            found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram.lower() in SKILLS_DB:\n",
    "            found_skills.add(ngram)\n",
    "    return found_skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resume(resume_text, output_file_path):\n",
    "#def parse_resume(resume_text):\n",
    "    name = extract_names(resume_text)\n",
    "    email = extract_emails(resume_text)\n",
    "    phone = extract_phone_number(resume_text)\n",
    "    skills = extract_skills(resume_text)\n",
    "    education = extract_education(resume_text)\n",
    "    \n",
    " # Replace empty lists with a single empty string\n",
    "    name = name or ['']\n",
    "    email = email or ['']\n",
    "    phone = phone or ['']\n",
    "    skills = skills or ['']\n",
    "    education = education or ['']\n",
    "    info = {\n",
    "        \"Name\": name,\n",
    "        \"Email\": email,\n",
    "        \"Phone\": phone,\n",
    "        \"Skills\": skills,\n",
    "        \"education\":education\n",
    "    }\n",
    "    print (info)\n",
    "    with open(output_file_path, 'a') as f:\n",
    "        f.write(tabulate(info, headers=\"keys\"))\n",
    "        f.write(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_name: 1.pdf\n",
      "{'Name': 'Avishek Kumar Data Scientist Machine Learning', 'Email': ['aviw.upes01@gmail.com'], 'Phone': '+91999900011 05', 'Skills': {'Python', 'Machine Learning'}}\n",
      "File_name: 10.pdf\n",
      "{'Name': 'Economics Moscow Advanced Machine Learning', 'Email': [''], 'Phone': '91 863465923 3', 'Skills': {'Python', 'team work', 'Machine Learning', 'python', 'communication', 'Data Science'}}\n",
      "File_name: 11.pdf\n",
      "{'Name': 'Khan Enthusiastic', 'Email': ['fulkarkhan9980@gmail.com'], 'Phone': '8443405050', 'Skills': {'machine learning', 'data science', 'Python', 'Data Science', 'Machine Learning'}}\n",
      "File_name: 12.pdf\n",
      "{'Name': 'Kunika Bhargav Data Science', 'Email': ['bhargav496@gmail.com'], 'Phone': '7983924436', 'Skills': {'Python', 'Data Science', 'Machine Learning'}}\n",
      "File_name: 13.pdf\n",
      "{'Name': 'Face API', 'Email': ['gkapil8019@gmail.com'], 'Phone': '9522330896', 'Skills': {'machine learning', 'data science', 'Python', 'Data Science', 'DATA SCIENCE'}}\n",
      "File_name: 14.pdf\n",
      "{'Name': 'Machine', 'Email': ['pvkanohara@gmail.com'], 'Phone': '+11-7192698493', 'Skills': {'machine learning', 'data science', 'Python', 'Machine Learning', 'python', 'Data Science', 'Machine learning'}}\n",
      "File_name: 15.pdf\n",
      "{'Name': 'Khan Address House', 'Email': [''], 'Phone': [''], 'Skills': {'machine learning', 'data science', 'Python', 'Data Science', 'Machine Learning', 'Machine learning'}}\n",
      "File_name: 16.pdf\n",
      "{'Name': 'Certified Associate Java', 'Email': [''], 'Phone': [''], 'Skills': {'Python', 'Machine Learning', 'Data Science', 'Machine learning', 'data Science'}}\n",
      "File_name: 17.pdf\n",
      "{'Name': 'Shukla Mobile', 'Email': ['a54@gmail.com'], 'Phone': '+11- 9591213356', 'Skills': {'Python', 'machine learning', 'Machine Learning', 'communication'}}\n",
      "File_name: 18.pdf\n",
      "{'Name': 'Farukh Sharma', 'Email': [''], 'Phone': '+91 8234540343', 'Skills': {'Python', 'Machine Learning', 'Data Science', 'Communication'}}\n",
      "File_name: 19.pdf\n",
      "{'Name': 'Skills Data Scientist', 'Email': ['sinha2010@gmail.con'], 'Phone': '+917734897148', 'Skills': {'machine learning', 'Communication', 'Python', 'Machine Learning', 'Machine learning'}}\n",
      "File_name: 2.pdf\n",
      "{'Name': 'Data Science Aspirant', 'Email': ['anmishamurarka@gmail.con'], 'Phone': '9199422433', 'Skills': {'machine learning', 'data science', 'Python', 'Data Science', 'Machine Learning'}}\n",
      "File_name: 20.pdf\n",
      "{'Name': 'Board Year Percent', 'Email': ['chawlasurili@gmail.com'], 'Phone': '+91-2382257665', 'Skills': {'Python', 'Data Science', 'Machine Learning'}}\n",
      "-------------File_name:------------- 21.docx\n",
      "{'Name': 'Mahajan', 'Email': [''], 'Phone': '+91-725445519', 'Skills': {'machine learning', 'Python', 'Machine Learning', 'python', 'communication', 'Machine learning'}}\n",
      "-------------File_name:------------- 22.docx\n",
      "{'Name': 'Sunit', 'Email': [''], 'Phone': [''], 'Skills': {'Python'}}\n",
      "-------------File_name:------------- 23.docx\n",
      "{'Name': 'Curriculum', 'Email': ['chandanalakhera35@gmail.com'], 'Phone': '6244330054', 'Skills': {'Team work', 'communication'}}\n",
      "Unsupported File Format: 24.png\n",
      "Unsupported File Format: 25.jfif\n",
      "Unsupported File Format: 26.jfif\n",
      "Unsupported File Format: 27.jpg\n",
      "Unsupported File Format: 28.jpeg\n",
      "Unsupported File Format: 29.jfif\n",
      "File_name: 3.pdf\n",
      "{'Name': 'Aankit Sharma Data Scientist', 'Email': ['aankit9418@gmail.com'], 'Phone': '+91 90940 79997', 'Skills': {'machine learning', 'Python', 'Machine Learning', 'Data Science', 'Machine learning'}}\n",
      "File_name: 4.pdf\n",
      "{'Name': 'Aashok Kumar', 'Email': ['aashokrekumar@gmail.com'], 'Phone': '+91-0176884977', 'Skills': {'machine learning', 'data science', 'Python', 'Data Science', 'Machine Learning'}}\n",
      "File_name: 5.pdf\n",
      "{'Name': 'Vijayan', 'Email': ['pswathinrp@gmail.com'], 'Phone': '9089319891', 'Skills': {'WEB DEVELOPMENT', 'machine learning', 'MACHINE LEARNING', 'PYTHON', 'Python'}}\n",
      "File_name: 6.pdf\n",
      "{'Name': 'Varsha', 'Email': [''], 'Phone': '+91 1121661342', 'Skills': {'Python', 'Machine Learning', 'python'}}\n",
      "File_name: 7.pdf\n",
      "{'Name': 'Lcomlinikanois', 'Email': ['kanoi43@gmail.com', 'kanoikumar43@gmail.com'], 'Phone': '+91 7978471213', 'Skills': {'data science', 'Communication', 'Python', 'Machine Learning', 'python'}}\n",
      "File_name: 8.pdf\n",
      "{'Name': 'Work Experience Infosys System Engineer', 'Email': [''], 'Phone': [''], 'Skills': {'Python', 'data science'}}\n",
      "File_name: 9.pdf\n",
      "{'Name': 'Tech Stack Pvthon Jupyter Notebook Morar Gwalior Objective', 'Email': ['ohitifha.mi58@gmail.com'], 'Phone': '7987743912', 'Skills': {'machine learning', 'Python', 'Data Science', 'python', 'Data science', 'Machine learning', 'DATA SCIENCE'}}\n",
      "Unsupported File Format: prog2.ipynb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Directory containing candidate resumes (PDF, DOCX, and images)\n",
    "    directory = 'C:/Users/user/Documents/GOMYCODE/ResumeParsing/dataset' \n",
    "    for filename in os.listdir(directory):\n",
    "        output_file_path = 'C:/Users/user/Documents/GOMYCODE/ResumeParsing/output.txt'\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(file_path) and (file_path.lower().endswith('.pdf') or file_path.lower().endswith('.png') or file_path.lower().endswith('.jpg'))  :\n",
    "            #resume_text = extract_text_from_pdf(file_path)\n",
    "            resume_text=extract_text_from_pdf_or_image(file_path)\n",
    "            print('File_name:', filename)\n",
    "            #print(resume_text)\n",
    "            parse_resume(resume_text,output_file_path)\n",
    "        elif os.path.isfile(file_path) and file_path.lower().endswith('.docx'):\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "            print('-------------File_name:-------------', filename)\n",
    "            #print(resume_text)\n",
    "            parse_resume(resume_text ,output_file_path)\n",
    "            \n",
    "        # elif os.path.isfile(file_path) and file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        #     resume_text = extract_text_from_image(file_path)\n",
    "        #     print('**************File_name:*****************', filename)\n",
    "        #     parse_resume(resume_text ,output_file_path)\n",
    "        else:\n",
    "            print('Unsupported File Format:', filename)\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
